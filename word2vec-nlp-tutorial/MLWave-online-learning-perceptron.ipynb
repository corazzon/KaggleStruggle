{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 노트북은 아래에 있는 MLWave에 올라온 글을 한국어로 번역하고 몇 가지 내용을 추가한 것입니다.\n",
    "\n",
    "# [Online Learning Perceptron From MLWave](https://mlwave.com/online-learning-perceptron/)\n",
    "\n",
    "* 소스코드 출처\n",
    "    * https://github.com/MLWave/online-learning-perceptron\n",
    "    * https://github.com/MLWave/online-learning-perceptron/blob/master/perceptron.py\n",
    "    * 위 소스코드를 Python3에서 실행되도록 일부 수정하였다.\n",
    "    \n",
    "* 온라인 학습 퍼셉트론\n",
    "\n",
    "* 퍼셉트론 : 가장 단순한 인공신경망이다. 이 글은 1943년에 고안된 개념에서 2015년 Kaggle 경진대회(영화 리뷰가 긍정인지 부정인지 예측)로 옮겨간다. NLP 감정 분석 작업에서 하나의 인공 신경 세포가 0.95 AUC를 얻을 수 있음을 보여준다.\n",
    "\n",
    "\n",
    "## 인공 신경망의 탄생 McCulloch-Pitts Neuron\n",
    "          \n",
    "<img src='https://s3.amazonaws.com/s3.timetoast.com/public/uploads/photos/7051972/descarga_%281%29.jpg?1477761390' width='200'>\n",
    "          \n",
    "인공 신경망에 기인한 네트워크를 분석하고 그들이 어떻게 간단한 논리적 기능을 하는지 보여주었다. 그들은 후에 신경 네트워크라 부르는 기술을 첫번째로 연구한 사람이다.\n",
    "          \n",
    " 신경 학자 인 McCulloch과 논리학자인 Pitts라는 두 연구자가 1943 년의 논문 “a Logical Calculus of the Ideas Immanent in Nervous Activity”(신경 행동에서 내재적 사고의 논리적 계산) 으로 시작되었다.\n",
    "* 논문링크 : https://link.springer.com/article/10.1007%2FBF02478259\n",
    "* [인공지능 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5)\n",
    "\n",
    "McCulloch는 신경 활동에 ‘all-or-nothing’활동이 있다고 추론했다. 활성화 임계 값에 도달하거나(출력 1) 출력하지 않으면 (출력 0) 신경세포가 발화한다.\n",
    "피츠 (Pitts)는 그러한 신경 학적 원칙을 사용하여 명제 논리를 포착 할 수있는 잠재력을보고 이해했다.\n",
    "\n",
    "<img src='https://mlwave.com/wp-content/uploads/2015/01/mccullogpitts.png'>\n",
    "McCulloch-Pitts 논문에서 뉴런의 회로도(looping 뉴런과 net)\n",
    "\n",
    "* 예를 들어, 새가 씨앗과 같이 작은 물체를 먹으려고 한다. 이 행동을 표로 나타내면 다음과 같다.\n",
    "\n",
    "|OBJECT|BROWN?|\tROUND?|\tEAT?|\n",
    "|:---|:---:|---:|:---|\n",
    "|Seed|\t1|\t1|\t1|\n",
    "|Leaf|\t1|\t0|\t0|\n",
    "|Golf Ball|\t0|\t1|\t0|\n",
    "|Key|\t0|\t0|\t0|\n",
    "\n",
    "\n",
    "* AND 연산\n",
    "McCulloch-Pitts Neuron으로 위 표를 모델링 할 수 있다. 활성화 임계 값을 1.5로 설정하면 \"BROWN\"및 \"ROUND\"속성이 모두 충족 될 때만 뉴런이 실행된다. 그러면 입력 합계는 2 (1 + 1)로 1.5의 활성화 임계 값보다 크다.\n",
    "\n",
    "\n",
    "<img src='https://mlwave.com/wp-content/uploads/2015/01/pitts-neuron.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 퍼셉트론\n",
    "출처 : [퍼셉트론 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0)\n",
    "\n",
    "<img src='http://www.enzyklopaedie-der-wirtschaftsinformatik.de/Members/wilex4/Rosen-2.jpg/image_preview'>\n",
    "\n",
    "퍼셉트론(perceptron)은 인공신경망의 한 종류로서, 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)에 의해 고안되었다. 이것은 가장 간단한 형태의 피드포워드(Feedforward) 네트워크 - 선형분류기- 으로도 볼 수 있다.\n",
    "퍼셉트론 알고리즘은 하드웨어로 구현 된 최초의 인공 신경망이었다.\n",
    "\n",
    "1960년 코넬 항공 연구소의 연구원은 미 해군 연구청의 자금으로 무작위로 400개의 광전지를 하나의 퍼셉트론에 연결하여 \"마크 1 퍼셉트론 (Mark 1 perceptron)\"이 탄생해 이것으로 기본 이미지 인식이 가능했다.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/5/52/Mark_I_perceptron.jpeg\">\n",
    "이미지 출처 : https://en.wikipedia.org/wiki/Perceptron\n",
    "\n",
    "퍼셉트론이 동작하는 방식은 각 노드의 가중치와 입력치를 곱한 것을 모두 합한 값이 활성함수에 의해 판단되는데, 그 값이 임계치(보통 0)보다 크면 뉴런이 활성화되고 결과값으로 1을 출력한다. 뉴런이 활성화되지 않으면 결과값으로 -1을 출력한다.\n",
    "\n",
    "마빈 민스키와 시모어 페퍼트는 저서 \"퍼셉트론\"에서 단층 퍼셉트론은 XOR 연산이 불가능하지만, 다층 퍼셉트론으로는 XOR 연산이 가능함을 보였다.\n",
    "\n",
    "#### 가중치\n",
    "\n",
    "퍼셉트론은 지도학습 분류기의 일종이다. 이전 값에 대한 학습으로 예측을 한다.\n",
    "\n",
    "퍼셉트론은 들어오는 연결에 가중치를 할당하여 작동한다. McCulloch-Pitts Neuron을 사용하여 들어오는 연결에서 값의 합계를 구하고 다음 특정 임계 값보다 높거나 낮은 지 확인했다. 내적을 구하는 대신 퍼셉트론을 사용했다. 여기에서는 들어오는 각 값에 가중치를 곱해서 합계를 구했다. \n",
    "\n",
    "\n",
    "`sum: (value1 * weight1) + (value2 * weight2)`\n",
    "\n",
    "`weights[feature_index] += learning_rate * error * feature_value`\n",
    "\n",
    "\n",
    "## 온라인 학습 Perceptron in Python\n",
    "파이썬으로 위의 퍼셉트론 알고리즘을 구현하며 스크립트가 PyPy(3-4배의 속도 향상)에서 실행되므로 표준 라이브러리를 사용하므로 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다.\n",
    "\n",
    "다음 경진대회에서 Vowpal Wabbit을 통한 해시트릭을 사용하였고 코드가 공개되어 있다.\n",
    "* [Display Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.](https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10322)\n",
    "* 코드 : https://kaggle2.blob.core.windows.net/forum-message-attachments/53646/1539/fast_solution.py\n",
    "\n",
    "\n",
    "## 온라인 학습\n",
    "퍼셉트론은 온라인 학습이 가능하다(한 번에 하나씩 샘플을 통해 학습). 메모리에 전체 데이터 세트가 필요하지 않으므로 더 큰 데이터 세트에 유용하다. 여기에서는 Vowpal Wabbit에서 온라인 학습 코드를 가져왔다.\n",
    "* [Vowpal Wabbit (Fast Learning)](http://hunch.net/~vw/)\n",
    "\n",
    "## 해싱 트릭\n",
    "벡터화 해싱 트릭은 Vowpal Wabbit(John Langford)에서 시작되었다. 이 트릭은 퍼셉트론으로 들어오는 연결 수를 고정 된 크기로 설정한다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'movie', 'sucks']\n",
      "[(272, 1), (696, 1), (797, 1)]\n"
     ]
    }
   ],
   "source": [
    "sample = \"This movie sucks\"\n",
    "fixed_size = 1024\n",
    "\n",
    "print(sample.split())\n",
    "\n",
    "features = [(hash(f)%fixed_size,1) for f in sample.split()]\n",
    "\n",
    "# list of tuples in form (feature_index,feature_value)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로 그레시브 검증 손실\n",
    "한 번에 하나씩 표본을 학습하면 점진적으로 train loss가 된다. 모델이 타겟을 보지않고 첫 샘플을 보고 예측을 한다.\n",
    "그런 다음이 예측을 대상 레이블과 비교하여 오류율을 계산 한다. 오류율이 낮으면 좋은 모델에 가깝다.\n",
    "\n",
    "### Multiple passes\n",
    "Vowpal Wabbit을 사용하면 학습률이 떨어지는 데이터 집합을 여러 번 통과시킬 수 있습니다.\n",
    "\n",
    "오류율이 낮아지면 데이터 세트를 여러 번 실행할 수도 있다. 트레이닝 데이터가 선형 적으로 분리 가능한 경우, 퍼셉트론은 트레이닝 세트에서에서 오차가 0으로 수렴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33554432"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opts[\"D\"] 여기에 있는 코드에서는 고정 값으로 다음의 값을 사용한다.\n",
    "2 ** 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 코드에서는 pandas, numpy, scipy같은 라이브러리를 사용하지 않고 파이썬에 내장 된 기능만을 사용해 학습하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from math import exp, log\n",
    "from datetime import datetime\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \"\"\"\n",
    "        Returns a cleaned, lowercased string\n",
    "        텍스트 데이터를 정제하고 소문자로 변환해 준다.\n",
    "    \"\"\"\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset,opts):\n",
    "    \"\"\"\n",
    "    Running through data in an online manner\n",
    "    Parses a tsv file for this competition and yields label, identifier and features\n",
    "    output:\n",
    "            label: int, The label / target (set to \"1\" if test set)\n",
    "            id: string, the sample identifier\n",
    "            features: list of tuples, in the form [(hashed_feature_index,feature_value)]\n",
    "            \n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] 형식의 튜플 목록\n",
    "    \"\"\"\n",
    "    for e, line in enumerate(open(loc_dataset,\"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "\n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2])\n",
    "                except:\n",
    "                    r[1] = clean(r[1])\n",
    "\n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            #  Vowpal Wabbit의 해시트릭을 사용한다.            \n",
    "            if len(r) == 3: # train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: #test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(features,weights):\n",
    "    \"\"\"\n",
    "    Calculate dot product from features and weights\n",
    "    input:\n",
    "            features: A list of tuples [(feature_index,feature_value)]\n",
    "            weights: the hashing trick weights filter, \n",
    "            note: length is max(feature_index)\n",
    "    output:\n",
    "            dotp: the dot product\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    # Running training passes\n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "            \n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            \n",
    "            # 다음 perceptron은 샘플의 레이블을 본다. \n",
    "            # 예측이 정확하다면, 오류는 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 오류는 \"-1\"또는 \"1\"이고 퍼셉트론은 다음과 같이 가중치를 업데이트한다.\n",
    "            # error is 1 if misclassified as 0, error is -1 if misclassified as 1\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp \n",
    "        \n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "\n",
    "        #Oh heh, we have overfit :)\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    #Initializing the weights\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    #Running training passes\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            # error is 1 if misclassified as 0, error is -1 if misclassified as 1\n",
    "            error = label - dp \n",
    "            \n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                # 가중치 업데이트\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        # Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),e+1,datetime.now()-start))\n",
    "\n",
    "        # Oh heh, we have overfit :)\n",
    "        # 오버피팅 되면 엄춘다.\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset,weights,opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "\n",
    "    # normalizing dotproducts between 0 and 1 \n",
    "    # 내적을 구해 0과 1로 일반화 한다.\n",
    "    # TODO: proper probability (bounded sigmoid?), online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) #appending normalized to predictions\n",
    "\n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5611\t\t0.77556\t\t25000\t\t0:00:17.465042\n",
      "2\t\t3204\t\t0.87184\t\t25000\t\t0:00:33.162966\n",
      "3\t\t2203\t\t0.91188\t\t25000\t\t0:00:50.881119\n",
      "4\t\t1624\t\t0.93504\t\t25000\t\t0:01:06.260245\n",
      "5\t\t1306\t\t0.94776\t\t25000\t\t0:01:24.930732\n",
      "6\t\t1019\t\t0.95924\t\t25000\t\t0:01:44.274250\n",
      "7\t\t776\t\t0.96896\t\t25000\t\t0:02:02.984444\n",
      "8\t\t627\t\t0.97492\t\t25000\t\t0:02:19.874557\n",
      "9\t\t543\t\t0.97828\t\t25000\t\t0:02:37.631447\n",
      "10\t\t442\t\t0.98232\t\t25000\t\t0:02:53.684940\n",
      "11\t\t371\t\t0.98516\t\t25000\t\t0:03:09.397923\n",
      "12\t\t309\t\t0.98764\t\t25000\t\t0:03:26.968180\n",
      "13\t\t303\t\t0.98788\t\t25000\t\t0:03:43.400317\n",
      "14\t\t272\t\t0.98912\t\t25000\t\t0:03:59.608439\n",
      "15\t\t214\t\t0.99144\t\t25000\t\t0:04:16.344165\n",
      "16\t\t186\t\t0.99256\t\t25000\t\t0:04:33.146372\n",
      "17\t\t132\t\t0.99472\t\t25000\t\t0:04:47.938968\n",
      "18\t\t110\t\t0.9956\t\t25000\t\t0:05:03.584521\n",
      "19\t\t74\t\t0.99704\t\t25000\t\t0:05:19.034022\n",
      "20\t\t70\t\t0.9972\t\t25000\t\t0:05:33.927663\n",
      "21\t\t44\t\t0.99824\t\t25000\t\t0:05:50.157100\n",
      "22\t\t78\t\t0.99688\t\t25000\t\t0:06:06.139316\n",
      "23\t\t88\t\t0.99648\t\t25000\t\t0:06:21.298486\n",
      "24\t\t67\t\t0.99732\t\t25000\t\t0:06:37.034139\n",
      "25\t\t104\t\t0.99584\t\t25000\t\t0:06:52.790791\n",
      "26\t\t80\t\t0.9968\t\t25000\t\t0:07:07.560694\n",
      "27\t\t107\t\t0.99572\t\t25000\t\t0:07:22.887636\n",
      "28\t\t66\t\t0.99736\t\t25000\t\t0:07:38.720910\n",
      "29\t\t33\t\t0.99868\t\t25000\t\t0:07:54.685332\n",
      "30\t\t23\t\t0.99908\t\t25000\t\t0:08:11.644299\n",
      "31\t\t17\t\t0.99932\t\t25000\t\t0:08:28.576857\n",
      "32\t\t15\t\t0.9994\t\t25000\t\t0:08:45.007793\n",
      "33\t\t14\t\t0.99944\t\t25000\t\t0:09:00.937147\n",
      "34\t\t27\t\t0.99892\t\t25000\t\t0:09:16.400320\n",
      "35\t\t23\t\t0.99908\t\t25000\t\t0:09:32.018908\n",
      "36\t\t4\t\t0.99984\t\t25000\t\t0:09:47.375040\n",
      "37\t\t5\t\t0.9998\t\t25000\t\t0:10:02.995867\n",
      "38\t\t47\t\t0.99812\t\t25000\t\t0:10:19.489474\n",
      "39\t\t12\t\t0.99952\t\t25000\t\t0:10:34.775243\n",
      "40\t\t13\t\t0.99948\t\t25000\t\t0:10:49.368176\n",
      "41\t\t28\t\t0.99888\t\t25000\t\t0:11:05.322494\n",
      "42\t\t5\t\t0.9998\t\t25000\t\t0:11:22.094194\n",
      "43\t\t25\t\t0.999\t\t25000\t\t0:11:39.471790\n",
      "44\t\t15\t\t0.9994\t\t25000\t\t0:11:54.024334\n",
      "45\t\t23\t\t0.99908\t\t25000\t\t0:12:09.636959\n",
      "46\t\t9\t\t0.99964\t\t25000\t\t0:12:26.499402\n",
      "47\t\t0\t\t1.0\t\t25000\t\t0:12:41.294914\n",
      "0 errors found during training, halting\n",
      "CPU times: user 12min 24s, sys: 4.77 s, total: 12min 29s\n",
      "Wall time: 12min 41s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0\n",
    "opts[\"clean\"] = True # clean the text a little\n",
    "opts[\"2grams\"] = True # add 2grams\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"data/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12701\t\t0.49196\t\t25000\t\t0:00:15.718587\n",
      "Done testing in 0:00:15.737001\n",
      "CPU times: user 15.4 s, sys: 132 ms, total: 15.5 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "# testing and saving predictions into preds\n",
    "%time preds = test_tron(\"data/testData.tsv\",weights,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"12311_10\"', 1, 73.95880416574607, 0.6350582685904541],\n",
       " ['\"8348_2\"', 0, -93.99075768392858, 0.4669811320754711],\n",
       " ['\"5828_4\"', 0, -0.138629436112021, 0.5609045504994442],\n",
       " ['\"7186_2\"', 0, -3.3271064666877583, 0.5577136514983344],\n",
       " ['\"12128_7\"', 1, 28.973552147405652, 0.5900388457269691],\n",
       " ['\"2913_8\"', 1, 63.769540611514955, 0.6248612652608204],\n",
       " ['\"4396_1\"', 0, -36.94474472384511, 0.524070477247502],\n",
       " ['\"395_2\"', 0, -0.9704060527839578, 0.5600721420643722],\n",
       " ['\"10616_1\"', 0, -85.88093567137707, 0.4750971143174246],\n",
       " ['\"9074_9\"', 0, -37.49926246829306, 0.5235155382907872]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing kaggle submission\n",
    "# 캐글 점수 제출을 위한 서브미션 파일을 작성한다.\n",
    "with open(\"data/submit_perceptron.csv\",\"wb\") as outfile:\n",
    "    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n",
    "    for p in sorted(preds):\n",
    "        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2231833910034602"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐글 스코어 0.95338\n",
    "129/578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>73.958804</td>\n",
       "      <td>0.635058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-93.990758</td>\n",
       "      <td>0.466981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.138629</td>\n",
       "      <td>0.560905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.327106</td>\n",
       "      <td>0.557714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>28.973552</td>\n",
       "      <td>0.590039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1          2         3\n",
       "0  \"12311_10\"  1  73.958804  0.635058\n",
       "1    \"8348_2\"  0 -93.990758  0.466981\n",
       "2    \"5828_4\"  0  -0.138629  0.560905\n",
       "3    \"7186_2\"  0  -3.327106  0.557714\n",
       "4   \"12128_7\"  1  28.973552  0.590039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐글에 제출할 때 바이너리 타입으로 제출하라고 되어 있는데 여기에서는 바이너리로 변환하지 않은 채 제출을 했다.\n",
    "# 그런데 캐글에서 점수가 평가되고 심지어 높은 점수로! \n",
    "# 그래서 다시 바이너리 형태의 예측값을 제출했더니 점수가 낮아졌다. \n",
    "# 바이너리로 제출한 스코어가 훨씬 낮은 0.89132 가 나왔지만 튜토리얼에 있는 방법을 사용했을 때보다 훨씬 높은 스코어다.\n",
    "# 머신러닝 패키지를 사용하지 않고 파이썬의 내장 기능을 통해서 이런 점수가 나올 수 있다는 것에 놀랐다.\n",
    "import pandas as pd\n",
    "\n",
    "presult = pd.DataFrame(preds)\n",
    "presult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    12701\n",
       "1    12299\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = presult[1].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 상위 벤치 마크\n",
    "포럼에서 현재 가장 좋은 벤치 마크 는 Abhishek 의 로지스틱 회귀 스크립트다. 리더 보드에서 0.95 AUC 를 얻기 위해 학습과 테스트 세트의 메모리 안에서 tfidf-fit_transform을 사용한다. 여기에서는 이 변환을 건너 뛰고 온라인 해시 벡터 라이저를 사용한다.\n",
    "\n",
    "Abhishek의 스크립트처럼 기능에서 2-gram(\"좋지 않은\"등)을 생성한다. 2-gram을 단순히 해쉬하고 샘플 벡터에 추가한다.\n",
    "\n",
    "또, 문자를 소문자로 바꾸고 영숫자가 아닌 것을 제거함으로써 텍스트를 조금 더 빠르게 정제한다.\n",
    "\n",
    "### 예측\n",
    "AUC를 최적화하기 위해 \"1\"또는 \"0\"예측만 제출하지 않는다. 이것은 약 0.88의 AUC를 줄 것이다. `여기에서는 0과 1 사이에서 정규화 된 dotproduct를 제출한다.`\n",
    "\n",
    "이 스크립트는 Abhishek의 솔루션 0.952 점수와 비교해 본다. 하지만 이 코드는 단지 몇 MB의 메모리를 필요로하며, tfidf 변환을 수행하지 않고 단지 2분 만에 0의 학습오류에 수렴한다다.\n",
    "\n",
    "텍스트 정제와 2-gram이 없으면 스크립트는 60초 이내에 실행되고 0.93의 점수를 산출한다.\n",
    "\n",
    "\n",
    "## 결론\n",
    "\"절대적인 지식은 없다. 모든 것은 확률에 의해서만 이루어진다 \" - Gödel (1961)\n",
    "\n",
    "0-1 임계 값 활성화가 적용된 매우 기본적인 퍼셉트론은 NLP 경진대회에서 잘 동작한다. 여기에서는 1957 알고리즘을 전혀 변경하지 않았다. 해싱 트릭을 없애고 비슷하거나 약간 더 좋은 점수를 받을 수 있다.\n",
    "\n",
    "이 스크립트는 확률을 출력 할 수 없다. dotproduct에 bounded sigmoid를 사용하여 출력의 온라인 정규화 형태를 얻거나 tinrtgu의 스크립트를 더 보완해 볼 수 있을 것이다.\n",
    "\n",
    "단일 노드 단일 레이어 퍼셉트론은 비선형 함수를 모델링 할 수 없으므로 더 나은 NLP 출력을 얻으려면 FFN(feedforward nets), recurrent nets, self-organizing maps, MLP(Multi-layer Perceptrons), word2vec 및 extreme learning machine (백프로파게이션이 없는 fast ffnets)을 봐야할 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
